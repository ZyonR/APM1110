---
title: "Summative Assessment 1"
author: "Ramilo, Zion John Yousef T., Dacanay, Jordan"
date: "`r Sys.Date()`"
output: html_document
---
# Defective Product Probability - Text Description

Create a program such that it takes 6 inputs 3 of which are the partition of products produced by each factories and the other 3 dictates that, given this factory this is it's defective rate or its proportion of defective, calculate the probability a random product drawn is defective?

* **Proportion of Products from Factories:** Enter a numerical value between 0.1 and 0.4 (inclusive) all factories must equal 1.
* **Defect Rate for each Factories:** Enter a numerical value between 0.01 and 0.05 all factories must equal 0.12. (inclusive).

```{r}
productProportions <- c()
productDefectives <- c()
while(T){
  ask <- readline(prompt = "Enter the proportion of products (between 0.1 and 0.4): ")
  ask <- as.numeric(ask)
  if(ask>0.4 | ask<0.1 ){
    print(paste("invalid number:",ask))
    next
  }else{
    productProportions<-c(productProportions,ask)
  }
  ask1 <- readline(prompt = "Enter the defective rate (between 0.01 and 0.05): ")
  ask1 <- as.numeric(ask1)
  if(ask1<0.01 |ask1>0.05){
    print(paste("invalid number:",ask1))
    next
  }else{
    productDefectives<-c(productDefectives,ask1)
  }
  if(length(productProportions)==2){
    ask<-1-sum(productProportions)
    ask1<-0.12-sum(productDefectives)
    productProportions<-c(productProportions,ask)
    productDefectives<-c(productDefectives,ask1)
      break
    }
}
defectives<-sum(productProportions*productDefectives)
print(paste("Probability that it is defective is: ",defectives))
```
By generating 10,000 searches in R, carry out a simulation experiment for a search engine going through a list of sites for a given key phrase, until the key phrase is found. You should allow your program to input the probability p that any site will contain the key phrase.

Plot the simulated pdf and calculate its mean and variance
```{r}
user_probability <- as.numeric(readline(prompt = "Input Probability: "))
geom_dist <- rgeom(10000,user_probability)
geom_dist_df <- data.frame("n_failures_before_success" = geom_dist) %>%
  group_by(n_failures_before_success) %>% 
    summarize("count" = n()/10000)
geom_dist_df_2 <- data.frame("n_failures_before_success" = geom_dist)
weighted_mean <- mean(geom_dist)
weighted_variance <- var(geom_dist)

ggplot(geom_dist_df,mapping = aes(x=n_failures_before_success,y=count))+
  geom_line(col='red', size=0.5)+
  geom_point()+
  labs(x="# of Trials Before Keyword was found",
       y="Probability Density Function",
       title = "Generated 10,000 searches until Key Phrase is Found",
       subtitle = paste("Mean: ",round(weighted_mean,3)," Variance: ",round(weighted_variance,3)))

```


Obtain the simulated conditional distribution of searches when three searches have been carried out without success. Calculate its mean and variance, and satisfy yourself that they are equivalent to the simulated distribution of the complete set.
```{r}
print(paste("Mean:",mean(geom_dist[geom_dist>3]-3),"Variance:",var(geom_dist[geom_dist>3]-3)))
```

As test data assume each site has a 60% chance of containing the key phrase.
To satisfy yourself that the Markov memory-less property holds, obtain estimates of P(X=4|X>3) and P(X=1), P(X=5|X>3) and P(X=2)

Using the geometric distribution formula:

$$

\text{P(X=4|x>3)} = \frac{\text{P(X=4} \cap {x>3)}}{\text{P(X>3)}}

$$
Given this we can say that the intersection of P(X=4) and P(X>3) is equivalent to P(X=4).
so we get.

$$

\text{P(X=4|x>3)} = \frac{\text{P(X=4)}}{\text{P(X>3)}}

$$

